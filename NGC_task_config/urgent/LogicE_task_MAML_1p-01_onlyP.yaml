action: ['train', 'valid', 'test']  # one of [train, train+valid, train+test, valid, test]
seed: 0
cuda: 0
data:
  type: EFO-1  # one of ['beta', 'EFO-1']
  data_folder: data/FB15k-237-betae-1p-01
  cpu: 10
load:
  load_model: False
  checkpoint_path: null
  step: 0
output:
  output_path: null  # can be null, which means it will be auto_generated
  prefix: EFO-1_log
train:
  train_method: 'MetaLearning'     # one of [MetaLearning, original]
  negative_sample_size: 128  # for each positive sample
  batch_size: 512
  learning_rate: 0.0001
  steps: 900000
  log_every_steps: 100
  warm_up_steps: 450000
  evaluate_every_steps: 900000
  save_every_steps: 15000
  interested_normal_forms:
    - 'DNF+MultiIU'
  formula_id_file: 'data/FB15k-237-betae/p_formulas.csv'
  use_freeze: False
  freeze_formula_file: 'data/FB15k-237-betae/freeze_formulas_dumps.csv'
  use_distance: False   #  one of [False, root, leaf]
evaluate:  # only used when valid/test in action
  batch_size: 1000
  print: true
  interested_normal_forms:
    - 'DNF'
    - 'DNF+MultiIU'
    - 'DeMorgan'
  formula_id_file: 'data/FB15k-237-betae/p_formulas.csv'
estimator:
  embedding: logic # one of [Transe, box, beta, dm]
  beta:
    entity_dim: 400
    relation_dim: 400
    hidden_dim: 1600
    num_layers: 2
    # evaluate_union: DM # one of [DM, DNF] after parsing it can be omitted
    gamma: 60
  box:
    entity_dim: 400
    relation_dim: 400
    offset_activation: None
    center_reg: 0.02
    gamma: 60
  dm:
    entity_dim: 2
    relation_dim: 2
    hidden_dim: 1600
    num_layers: 2
  logic:
    entity_dim: 400
    relation_dim: 400
    hidden_dim: 1600
    num_layers: 2
    gamma: 0.375
    t_norm: luk
    bounded: 0
    use_att: 1
    use_gtrans: 0
  cqd:
    entity_dim: 1000 # actually 2000
    relation_dim: 1000
    norm_type: product
  NewLook:
    entity_dim: 400
    relation_dim: 400
    center_reg: 0.2
    x_reg: 0.2 # \lambda in the paper
MetaLearning:
  Algorithm: MAML
  shrink_adapt_lr: False
  shrink_finetune_lr: False
  MAML:
    support_data_num: 10
    finetune_step: 5
    finetune_lr: 0.002
    adaptation_lr: 0.008
    adaptation_step: 1
    k_support: 1
    k_query: 15
    batch_size: 512
    test_batch_size: 1000
    test_outer_loss: False
    test_within_adaptation: False
  operator_MAML:
    support_data_num: 50
    finetune_step: 5
    finetune_lr: 0.001
    adaptation_lr: 0.004
    adaptation_step: 1
    k_support: 1
    k_query: 15
    batch_size: 512
    test_batch_size: 1000
    test_outer_loss: True
    test_within_adaptation: True




